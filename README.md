# Introduction to Computational Neuroscience (Theory)

This repository contains my course work for Computational Neuroscience (Theory), at ENS Cogmaster, 2024. It is organized by homework. 
The course focused on the mathematical foundations.

## Excercise 1: Perceptron & Hoppfield
This homework covers the basics of the perceptron: linear seperability, and update rules, as well as Hoppfield networks.  

## Excercise 2: Lecture notes
Not uploaded

## Excercise 3: Signal Detection Theory
This homework covers the basics of signal detection theory: working with gaussians, hit rates & false alarms, and Reciver-Operator Characteristic curves. 

## Excercise 4: Parameter Estimation
This homework covers the basics of parameter estimation and gradient descent. 

## Excercise 5: Covariance, Correlation, & Bayes Theorem
This homework covers the relationship between the correlation and covariance. It also covers the application of Bayes theorem in neural decoding. 

## Excercise 6: Exploration & Exploitation
This homework covers the exploration/exploitation tradeoff: temperature tuning, updating rules, and learning rate.

## Excercise 7: Temporal Difference Reinforcement Learning
This homework covers the basics of TD-RL: the temporal difference learning rule, and modeling the value function.
